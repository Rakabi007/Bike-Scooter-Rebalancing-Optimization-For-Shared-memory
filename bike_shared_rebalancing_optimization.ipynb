{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPrQtUhHTYaW7hLitPJ8dAN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rakabi007/Bike-Scooter-Rebalancing-Optimization-For-Shared-memory/blob/main/bike_shared_rebalancing_optimization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_4d78w9vXHJt"
      },
      "outputs": [],
      "source": [
        "import math, random, requests\n",
        "import numpy as np, pandas as pd, geopandas as gpd\n",
        "from shapely.geometry import Point\n",
        "import networkx as nx\n",
        "import folium\n",
        "from folium import FeatureGroup, LayerControl\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------- Config  -----------------\n",
        "SYSTEM      = \"PORTLAND_BIKETOWN\"   # or \"NASHVILLE_BCYCLE\", \"NYC_CITIBIKE\", \"PORTLAND_BIKETOWN\"\n",
        "GBFS_ROOT   = None                  # <-- force auto-pick; don't reuse a prior value\n",
        "TARGET_FILL = 0.45\n",
        "STATION_CAP = 2500\n",
        "K_NEAREST   = 3\n",
        "SEED        = 42\n",
        "BBOX = None\n",
        "\n",
        "random.seed(SEED); np.random.seed(SEED)\n",
        "\n",
        "\n",
        "# =========================\n",
        "# GBFS loader (robust) + UTM projection\n",
        "# =========================\n",
        "SYSTEMS = {\n",
        "    \"NYC_CITIBIKE\":      \"https://gbfs.citibikenyc.com/gbfs/gbfs.json\",         # docked\n",
        "    \"PORTLAND_BIKETOWN\": \"https://gbfs.biketownpdx.com/gbfs/gbfs.json\",         # hybrid/dockless supports virtual stations\n",
        "    \"NASHVILLE_BCYCLE\":  \"https://gbfs.bcycle.com/bcycle_nashville/gbfs.json\",  # may be sparse; still fine\n",
        "}\n",
        "\n",
        "def pick_gbfs_root(system, override=None):\n",
        "    if override is not None and str(override).strip():\n",
        "        return override\n",
        "    if system in SYSTEMS:\n",
        "        return SYSTEMS[system]\n",
        "    raise ValueError(\"Unknown system and no GBFS_ROOT provided.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "dUj0NKblajq_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_feed_url(root_json, feed_name, lang=\"en\"):\n",
        "    data = root_json.get(\"data\", {})\n",
        "    feeds = data.get(lang, data[next(iter(data))])[\"feeds\"]\n",
        "    for f in feeds:\n",
        "        if f[\"name\"] == feed_name:\n",
        "            return f[\"url\"]\n",
        "    raise KeyError(f\"Feed '{feed_name}' not found in GBFS root\")\n",
        "\n",
        "def read_json(url):\n",
        "    import requests\n",
        "    r = requests.get(url, timeout=30)\n",
        "    r.raise_for_status()\n",
        "    return r.json()\n",
        "\n",
        "def load_gbfs_stations(root_url):\n",
        "    root = read_json(root_url)\n",
        "    url_info   = get_feed_url(root, \"station_information\")\n",
        "    url_status = get_feed_url(root, \"station_status\")\n",
        "\n",
        "    info   = pd.DataFrame(read_json(url_info).get(\"data\", {}).get(\"stations\", []))\n",
        "    status = pd.DataFrame(read_json(url_status).get(\"data\", {}).get(\"stations\", []))\n",
        "\n",
        "    # Normalize IDs\n",
        "    if \"station_id\" not in info.columns and \"stationCode\" in info.columns:\n",
        "        info = info.rename(columns={\"stationCode\": \"station_id\"})\n",
        "    if \"station_id\" not in status.columns and \"stationCode\" in status.columns:\n",
        "        status = status.rename(columns={\"stationCode\": \"station_id\"})\n",
        "    if \"station_id\" not in info.columns or \"station_id\" not in status.columns:\n",
        "        raise KeyError(\"GBFS missing station_id/stationCode in one of the feeds\")\n",
        "\n",
        "    df = info.merge(status, on=\"station_id\", how=\"inner\", suffixes=(\"_info\", \"_status\"))\n",
        "\n",
        "    # Filter out virtual or non-installed / non-renting if present\n",
        "    def to_bool(x):\n",
        "        if isinstance(x, bool): return x\n",
        "        if pd.isna(x): return True\n",
        "        return str(x).strip().lower() in (\"1\",\"true\",\"yes\")\n",
        "    if \"is_virtual_station\" in df.columns:\n",
        "        df = df[~df[\"is_virtual_station\"].apply(to_bool)]\n",
        "    if \"is_installed\" in df.columns:\n",
        "        df = df[df[\"is_installed\"].apply(to_bool)]\n",
        "    if \"is_renting\" in df.columns:\n",
        "        df = df[df[\"is_renting\"].apply(to_bool)]\n",
        "\n",
        "    # Coerce lon/lat; some feeds use 'longitude'/'latitude'\n",
        "    if not {\"lon\",\"lat\"}.issubset(df.columns):\n",
        "        swap = {}\n",
        "        if \"longitude\" in df.columns: swap[\"longitude\"] = \"lon\"\n",
        "        if \"latitude\"  in df.columns: swap[\"latitude\"]  = \"lat\"\n",
        "        df = df.rename(columns=swap)\n",
        "    for c in (\"lon\",\"lat\"):\n",
        "        if c not in df.columns:\n",
        "            raise KeyError(\"No lon/lat in station_information\")\n",
        "        df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
        "\n",
        "    # Bikes/docks/capacity (fallbacks); some dockless systems have no docks\n",
        "    if \"num_bikes_available\" not in df.columns:\n",
        "        df[\"num_bikes_available\"] = 0\n",
        "    if \"num_docks_available\" not in df.columns:\n",
        "        df[\"num_docks_available\"] = 0\n",
        "    if \"capacity\" not in df.columns:\n",
        "        df[\"capacity\"] = df[\"num_bikes_available\"].fillna(0) + df[\"num_docks_available\"].fillna(0)\n",
        "\n",
        "    # Clean types\n",
        "    for c in (\"num_bikes_available\",\"num_docks_available\",\"capacity\"):\n",
        "        df[c] = pd.to_numeric(df[c], errors=\"coerce\").fillna(0).astype(int)\n",
        "\n",
        "    # Final tidy: drop invalid rows\n",
        "    before = len(df)\n",
        "    df = df.dropna(subset=[\"lon\",\"lat\"]).copy()\n",
        "    # Require positive capacity (skip free-floating ‘virtual’ points)\n",
        "    df = df[df[\"capacity\"] > 0].copy()\n",
        "    dropped = before - len(df)\n",
        "\n",
        "    out = pd.DataFrame({\n",
        "        \"id\":   df[\"station_id\"].astype(str),\n",
        "        \"name\": df.get(\"name\", df[\"station_id\"]),\n",
        "        \"lon\":  df[\"lon\"].astype(float),\n",
        "        \"lat\":  df[\"lat\"].astype(float),\n",
        "        \"cap\":  df[\"capacity\"].astype(int),\n",
        "        \"inv\":  df[\"num_bikes_available\"].astype(int),\n",
        "        \"docks\": df[\"num_docks_available\"].astype(int)\n",
        "    })\n",
        "    print(f\"Loaded GBFS stations (after cleaning): {len(out)}  | dropped={dropped}\")\n",
        "    return out.reset_index(drop=True)\n",
        "\n",
        "\n",
        "def safe_utm_crs_from_mean(lons, lats):\n",
        "    \"\"\"Fallback if estimate_utm_crs fails: compute UTM zone from mean lon/lat.\"\"\"\n",
        "    lon = float(np.nanmean(lons)); lat = float(np.nanmean(lats))\n",
        "    zone = int((lon + 180) // 6) + 1\n",
        "    epsg = 32600 + zone if lat >= 0 else 32700 + zone\n",
        "    return f\"EPSG:{epsg}\"\n"
      ],
      "metadata": {
        "id": "vVOEuDtUak8w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # ---- use the loader ----\n",
        "GBFS_ROOT = pick_gbfs_root(SYSTEM, GBFS_ROOT)\n",
        "print(f\"Using GBFS root for {SYSTEM}: {GBFS_ROOT}\")  # sanity check\n",
        "stations_ll = load_gbfs_stations(GBFS_ROOT)"
      ],
      "metadata": {
        "id": "Mlu2bzdDKC-F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Project to meters (UTM). Try GeoPandas auto; fallback to manual UTM if NaNs trigger an error.\n",
        "gdf = gpd.GeoDataFrame(stations_ll, geometry=gpd.points_from_xy(stations_ll.lon, stations_ll.lat), crs=4326)\n",
        "try:\n",
        "    CRS_UTM = gdf.estimate_utm_crs()\n",
        "except Exception:\n",
        "    CRS_UTM = safe_utm_crs_from_mean(stations_ll.lon.values, stations_ll.lat.values)\n",
        "\n",
        "gdf_m = gdf.to_crs(CRS_UTM)\n",
        "\n",
        "stations = pd.DataFrame({\n",
        "    \"id\": stations_ll[\"id\"],\n",
        "    \"name\": stations_ll[\"name\"],\n",
        "    \"lon\": stations_ll[\"lon\"],\n",
        "    \"lat\": stations_ll[\"lat\"],\n",
        "    \"xm\":  gdf_m.geometry.x.values,\n",
        "    \"ym\":  gdf_m.geometry.y.values,\n",
        "    \"cap\": stations_ll[\"cap\"],\n",
        "    \"inv\": stations_ll[\"inv\"],\n",
        "})\n"
      ],
      "metadata": {
        "id": "OlcFN-UsapsZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build targets and surplus/deficit as before\n",
        "stations[\"target\"]  = (TARGET_FILL * stations[\"cap\"]).round().astype(int)\n",
        "stations[\"surplus\"] = (stations[\"inv\"] - stations[\"target\"]).clip(lower=0).astype(int)\n",
        "stations[\"deficit\"] = (stations[\"target\"] - stations[\"inv\"]).clip(lower=0).astype(int)\n",
        "print(f\"Loaded stations: {len(stations)} (system={SYSTEM})\")\n",
        "\n"
      ],
      "metadata": {
        "id": "Kq7x8tpCKJJW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------- Simple K-nearest greedy rebalancing -----------------\n",
        "donors    = stations[stations.surplus > 0][[\"id\",\"xm\",\"ym\",\"surplus\"]].copy()\n",
        "receivers = stations[stations.deficit > 0][[\"id\",\"xm\",\"ym\",\"deficit\"]].copy()\n",
        "\n",
        "def euc(a,b): return math.hypot(a[0]-b[0], a[1]-b[1])\n",
        "\n",
        "shipments = []  # (from_id, to_id, qty)\n",
        "\n",
        "if not donors.empty and not receivers.empty:\n",
        "    # build K nearest receiver lists for each donor\n",
        "    recv_xy = receivers.set_index(\"id\")[[\"xm\",\"ym\",\"deficit\"]].to_dict(\"index\")\n",
        "    donor_rows = donors.to_dict(\"records\")\n",
        "\n",
        "    # maintain mutable deficits\n",
        "    rem_def = {rid: r[\"deficit\"] for rid, r in recv_xy.items()}\n",
        "\n",
        "    for d in donor_rows:\n",
        "        d_id, dx, dy, s = d[\"id\"], d[\"xm\"], d[\"ym\"], int(d[\"surplus\"])\n",
        "        if s <= 0: continue\n",
        "        # nearest K receivers by meters\n",
        "        dists = sorted(((rid, euc((dx,dy),(recv_xy[rid][\"xm\"], recv_xy[rid][\"ym\"])))\n",
        "                        for rid in recv_xy.keys()), key=lambda t: t[1])[:max(1, K_NEAREST)]\n",
        "        for rid, _ in dists:\n",
        "            if s <= 0: break\n",
        "            need = rem_def.get(rid, 0)\n",
        "            if need <= 0: continue\n",
        "            q = min(s, need)\n",
        "            shipments.append((d_id, rid, int(q)))\n",
        "            s       -= q\n",
        "            rem_def[rid] = need - q\n"
      ],
      "metadata": {
        "id": "wJ8guX9jKMIx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plan totals for popups\n",
        "plan_pick = {}\n",
        "plan_drop = {}\n",
        "for sid, tid, q in shipments:\n",
        "    plan_pick[sid] = plan_pick.get(sid,0) + q\n",
        "    plan_drop[tid] = plan_drop.get(tid,0) + q\n",
        "\n",
        "stations[\"to_pick\"] = stations[\"id\"].map(plan_pick).fillna(0).astype(int)\n",
        "stations[\"to_drop\"] = stations[\"id\"].map(plan_drop).fillna(0).astype(int)\n",
        "\n"
      ],
      "metadata": {
        "id": "smGr5O_LKQRm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------- KPIs / validation -----------------\n",
        "ship_total = sum(q for _,_,q in shipments)\n",
        "print(f\"\\nFlow check: shipped={ship_total}, surplus={int(stations.surplus.sum())}, deficit={int(stations.deficit.sum())}\")\n",
        "\n",
        "tmp = stations.set_index(\"id\")[[\"inv\",\"cap\"]].copy()\n",
        "for sid, tid, q in shipments:\n",
        "    tmp.at[sid, \"inv\"] -= q\n",
        "    tmp.at[tid, \"inv\"] += q\n",
        "viol_low  = int((tmp[\"inv\"] < 0).sum())\n",
        "viol_high = int((tmp[\"inv\"] > tmp[\"cap\"]).sum())\n",
        "mad_after = (tmp[\"inv\"] - (TARGET_FILL*tmp[\"cap\"]).round()).abs().mean()\n",
        "print(f\"Post-ship bounds violations → below 0: {viol_low}, above cap: {viol_high}\")\n",
        "print(f\"Mean |inv-target| after shipping: {mad_after:.2f} bikes\")"
      ],
      "metadata": {
        "id": "3EggjRS3KSz0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# shipment stats\n",
        "if shipments:\n",
        "    S = pd.DataFrame(shipments, columns=[\"from_id\",\"to_id\",\"qty\"])\n",
        "    idx = stations.set_index(\"id\")\n",
        "    S[\"sx\"], S[\"sy\"] = idx.loc[S[\"from_id\"], \"xm\"].values, idx.loc[S[\"from_id\"], \"ym\"].values\n",
        "    S[\"tx\"], S[\"ty\"] = idx.loc[S[\"to_id\"],   \"xm\"].values, idx.loc[S[\"to_id\"],   \"ym\"].values\n",
        "    S[\"dist_km\"] = np.hypot(S.sx - S.tx, S.sy - S.ty) / 1000.0\n",
        "    print(\"\\nShipment distance summary (km) and qty:\")\n",
        "    print(S[[\"qty\",\"dist_km\"]].describe().to_string(index=False))\n",
        "    S[[\"from_id\",\"to_id\",\"qty\",\"dist_km\"]].to_csv(\"shipments.csv\", index=False)\n",
        "    print(\"Wrote shipments.csv\")\n"
      ],
      "metadata": {
        "id": "Nb1txbtoKW27"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------- Map (two layers) -----------------\n",
        "# center\n",
        "cy, cx = stations[\"lat\"].median(), stations[\"lon\"].median()\n",
        "m = folium.Map(location=[cy, cx], zoom_start=12, tiles=\"cartodbpositron\")\n",
        "fg_st = FeatureGroup(name=\"Stations\", show=True)\n",
        "fg_sh = FeatureGroup(name=\"Shipments (greedy K-nearest)\", show=True)\n",
        "\n",
        "for _, r in stations.iterrows():\n",
        "    color = \"#1a9850\" if r.surplus>0 else \"#d73027\" if r.deficit>0 else \"#666\"\n",
        "    popup = (f\"<b>{r.name}</b> (id={r.id})<br>\"\n",
        "             f\"cap={r.cap}, inv={r.inv}, target={int(TARGET_FILL*r.cap)}<br>\"\n",
        "             f\"surplus={r.surplus}, deficit={r.deficit}<br>\"\n",
        "             f\"plan pick={r.to_pick}, drop={r.to_drop}\")\n",
        "    folium.CircleMarker([r.lat, r.lon], radius=3.5, color=color, fill=True, fill_opacity=0.95,\n",
        "                        popup=popup).add_to(fg_st)\n"
      ],
      "metadata": {
        "id": "L3eVOfwhKZvE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# draw shipments (thin blue)\n",
        "for sid, tid, q in shipments:\n",
        "    a = stations.loc[stations.id==sid, [\"lat\",\"lon\"]].iloc[0].tolist()\n",
        "    b = stations.loc[stations.id==tid, [\"lat\",\"lon\"]].iloc[0].tolist()\n",
        "    folium.PolyLine([a,b], color=\"#2b8cbe\", weight=2, opacity=0.5,\n",
        "                    tooltip=f\"{sid} → {tid} (q={q})\").add_to(fg_sh)\n",
        "\n",
        "fg_st.add_to(m); fg_sh.add_to(m)\n",
        "LayerControl(collapsed=False).add_to(m)\n",
        "out = f\"rebalancing_lite_{SYSTEM.lower()}.html\"\n",
        "m.save(out)\n",
        "print(\"Map saved:\", out)\n",
        "\n"
      ],
      "metadata": {
        "id": "H9iySrj-Kds9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------- Notes -----------------\n",
        "# If you later want VRP truck routes, plug the 'shipments' list into your OR-Tools section.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Using GBFS root for PORTLAND_BIKETOWN: https://gbfs.biketownpdx.com/gbfs/gbfs.json\n",
        "Loaded GBFS stations (after cleaning): 254  | dropped=0\n",
        "Loaded stations: 254 (system=PORTLAND_BIKETOWN)\n",
        "\n",
        "Flow check: shipped=107, surplus=145, deficit=599\n",
        "Post-ship bounds violations → below 0: 0, above cap: 1\n",
        "Mean |inv-target| after shipping: 2.09 bikes\n",
        "\n",
        "Shipment distance summary (km) and qty:\n",
        "      qty   dist_km\n",
        "60.000000 60.000000\n",
        " 1.783333  0.612019\n",
        " 1.026623  0.312627\n",
        " 1.000000  0.102715\n",
        " 1.000000  0.406652\n",
        " 2.000000  0.539201\n",
        " 2.000000  0.793715\n",
        " 6.000000  1.458119\n",
        "Wrote shipments.csv\n",
        "Map saved: rebalancing_lite_portland_biketown.html\n"
      ],
      "metadata": {
        "id": "Vq_jR2ZvKgXi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}